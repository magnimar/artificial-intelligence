{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"car_prices.csv\", chunksize=10000)\n",
    "\n",
    "cat_columns = [\n",
    "    'make', \n",
    "    'model', \n",
    "    'trim', \n",
    "    'body', \n",
    "    'transmission', \n",
    "    'state', \n",
    "    'color', \n",
    "    'interior', \n",
    "]\n",
    "\n",
    "numeric_column = [\n",
    "    'year', \n",
    "    'condition', \n",
    "    'odometer', \n",
    "    'mmr', \n",
    "    'sellingprice',\n",
    "    'days_since_sale'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, columns):\n",
    "    \"\"\"\n",
    "    One-hot encodes specified columns in a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(df[column], prefix=column)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize(df, columns):\n",
    "    \"\"\"\n",
    "    Normalizes specified columns in a pandas DataFrame between 0 and 1.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            year  condition  odometer       mmr  sellingprice  days_since_sale  make_BMW  make_Chevrolet  make_Chrysler  make_Dodge  make_Ford  make_Honda  make_Hyundai  make_Infiniti  make_Kia  make_Mazda  make_Mercedes-Benz  make_Nissan  make_Toyota  make_Volkswagen  make_other  model_1500  model_200  model_2500  model_3 Series  model_300  model_4Runner  model_5 Series  model_6 Series  model_7 Series  model_A4  model_A6  model_Acadia  model_Accent  model_Accord  model_Altima  model_Avalanche  model_Avalon  model_Avenger  model_C-Class  model_CC  model_CLK-Class  model_CR-V  model_CTS  model_CX-5  model_CX-9  model_Caliber  model_Camaro  model_Camry  model_Challenger  ...  model_Juke  model_MKS  trim_E350 Sport  trim_Two  model_Savana Cargo  trim_EL King Ranch  trim_GLK350  trim_GT Premium  state_wa  trim_SLE-1  model_Outlander Sport  trim_TDI  model_Versa Note  trim_King Ranch  trim_LX Hybrid  trim_PreRunner V6  trim_SR  model_Mazda5  trim_LTZ 1500  trim_E350 Luxury 4MATIC  \\\n",
      "0       1.000000      1.000  0.016638  0.137439      0.139605         0.371115       0.0               0            0.0           0          0         0.0           0.0            0.0       1.0         0.0                 0.0            0            0              0.0           0         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "1       1.000000      1.000  0.009392  0.139453      0.139605         0.371115       0.0               0            0.0           0          0         0.0           0.0            0.0       1.0         0.0                 0.0            0            0              0.0           0         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "2       0.965517      0.875  0.001330  0.213962      0.194800         0.316271       1.0               0            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            0            0              0.0           0         0.0        0.0         0.0               1          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "3       1.000000      0.775  0.014281  0.184427      0.180189         0.290676       0.0               0            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            0            0              0.0           1         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "4       0.965517      0.825  0.002640  0.442860      0.435061         0.367459       1.0               0            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            0            0              0.0           0         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "...          ...        ...       ...       ...           ...              ...       ...             ...            ...         ...        ...         ...           ...            ...       ...         ...                 ...          ...          ...              ...         ...         ...        ...         ...             ...        ...            ...             ...             ...             ...       ...       ...           ...           ...           ...           ...              ...           ...            ...            ...       ...              ...         ...        ...         ...         ...            ...           ...          ...               ...  ...         ...        ...              ...       ...                 ...                 ...          ...              ...       ...         ...                    ...       ...               ...              ...             ...                ...      ...           ...            ...                      ...   \n",
      "433993  0.904762      0.800  0.029170  0.151252      0.161994         0.816667       0.0               0            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            1            0              0.0           0         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "433994  0.857143      0.675  0.131005  0.235565      0.265836         0.816667       0.0               0            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            0            0              0.0           1         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "433995  0.857143      0.900  0.222012  0.083035      0.083074         0.900000       0.0               1            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            0            0              0.0           0         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "433996  0.857143      0.400  0.238272  0.228411      0.229491         0.600000       0.0               1            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            0            0              0.0           0         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "433997  0.857143      0.850  0.091636  0.113439      0.119418         0.816667       0.0               1            0.0           0          0         0.0           0.0            0.0       0.0         0.0                 0.0            0            0              0.0           0         0.0        0.0         0.0               0          0            0.0             0.0             0.0             0.0       0.0       0.0           0.0           0.0             0             0              0.0           0.0            0.0              0       0.0              0.0           0        0.0         0.0         0.0            0.0           0.0            0               0.0  ...         0.0        0.0              0.0       0.0                 0.0                 0.0          0.0              0.0       0.0         0.0                    0.0       0.0               0.0              0.0             0.0                0.0      0.0           0.0            0.0                      0.0   \n",
      "\n",
      "        model_Cooper Countryman  trim_E-350 Super Duty  body_Crew Cab  trim_Pop  model_CT 200h  model_QX80  trim_STX  model_XC60  trim_2.0 SR  trim_T5 Drive-E Premier  model_Venza  model_Tiguan  trim_2SS  model_Regal  model_500  model_Corvette  model_QX  model_fortwo  trim_LS 3500  trim_QX56  trim_T5 Drive-E  trim_Trekking  trim_passion coupe  model_Santa Fe Sport  state_co  color_red  model_JX  trim_JX35  body_G Sedan  state_sc  \n",
      "0                           0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "1                           0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "2                           0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "3                           0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "4                           0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "...                         ...                    ...            ...       ...            ...         ...       ...         ...          ...                      ...          ...           ...       ...          ...        ...             ...       ...           ...           ...        ...              ...            ...                 ...                   ...       ...        ...       ...        ...           ...       ...  \n",
      "433993                      0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "433994                      0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "433995                      0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "433996                      0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "433997                      0.0                    0.0            0.0       0.0            0.0         0.0       0.0         0.0          0.0                      0.0          0.0           0.0       0.0          0.0        0.0             0.0       0.0           0.0           0.0        0.0              0.0            0.0                 0.0                   0.0       0.0        0.0       0.0        0.0           0.0       0.0  \n",
      "\n",
      "[433998 rows x 600 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunksize = 10000\n",
    "one_hot_encoded_data = pd.DataFrame()\n",
    "\n",
    "for chunk in df:\n",
    "\n",
    "    # Drop the 'vin' column from the chunk\n",
    "    chunk.drop('vin', axis=1, inplace=True)\n",
    "\n",
    "    # Convert the 'saledate' column to datetime with timezone\n",
    "    chunk['saledate'] = pd.to_datetime(chunk['saledate'], utc=True, errors='coerce')\n",
    "\n",
    "    # Remove the timezone information\n",
    "    chunk['saledate'] = chunk['saledate'].dt.tz_localize(None)\n",
    "    \n",
    "    # Calculate the time since the sale using timezone-naive current datetime\n",
    "    chunk['days_since_sale'] = pd.Timestamp.now(tz=None) - chunk['saledate']\n",
    "\n",
    "    # Convert the timedelta to days\n",
    "    chunk['days_since_sale'] = chunk['days_since_sale'].dt.days\n",
    "\n",
    "    # Drop the 'saledate' column\n",
    "    chunk.drop('saledate', axis=1, inplace=True)\n",
    "    chunk.drop('seller', axis=1, inplace=True)\n",
    "\n",
    "    # Continue with the rest of the processing\n",
    "    \n",
    "    # get sum of all values in each column\n",
    "    \n",
    "    for column in cat_columns:\n",
    "    \n",
    "        make_frequency = chunk[column].value_counts().sort_values(ascending=False)\n",
    "\n",
    "        # Calculate the cumulative frequency distribution\n",
    "        cumulative_frequency = make_frequency.cumsum() / make_frequency.sum()\n",
    "\n",
    "        # Select categories in the top 80% of the frequency distribution\n",
    "        selected_categories = cumulative_frequency[cumulative_frequency <= 0.8].index\n",
    "\n",
    "        # Replace the other categories in the 'make' column with \"other\"\n",
    "        chunk[column] = chunk[column].apply(lambda x: x if x in selected_categories else 'other')\n",
    "    \n",
    "    chunk = normalize(chunk, numeric_column)\n",
    "    chunk = one_hot_encode(chunk, cat_columns)\n",
    "    \n",
    "    chunk.fillna(0.0, inplace=True)\n",
    "    \n",
    "    one_hot_encoded_data = pd.concat([one_hot_encoded_data, chunk], ignore_index=True)\n",
    "    \n",
    "    # print dimensions of the one-hot encoded data\n",
    "    \n",
    "one_hot_encoded_data.fillna(0.0, inplace=True)\n",
    "print(one_hot_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = one_hot_encoded_data.sample(frac=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = one_hot_encoded_data.drop(training_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor_x_training = torch.tensor(training_data.drop(columns=['sellingprice'], axis=1).values, dtype=torch.float32)\n",
    "tensor_y_training = torch.tensor(training_data['sellingprice'].values, dtype=torch.float32)\n",
    "\n",
    "print(tensor_x_training.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor_x_validation = torch.tensor(validation_data.drop(columns=['sellingprice'], axis=1).values, dtype=torch.float32)\n",
    "tensor_y_validation = torch.tensor(validation_data['sellingprice'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing out parameter:  32  and learning rate:  0.0001\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import torch.optim as optim\n",
    "# import time\n",
    "import time\n",
    "\n",
    "# parameters = [8, 16, 32, 64]\n",
    "# learning_rates = [0.0001, 0.001, 0.01]\n",
    "# \n",
    "# r2_min = {\"r2\": -1, \"parameter\": 0, \"learning_rate\": 0}\n",
    "\n",
    "#for parameter in parameters:\n",
    "#    for learning_rate in learning_rates:\n",
    "\n",
    "parameter = 32\n",
    "learning_rate = 0.0001\n",
    "        \n",
    "# print(\"current r2 min : \", r2_min)\n",
    "\n",
    "# start timer\n",
    "start = time.time()\n",
    "\n",
    "model = nn.Sequential(\n",
    "\n",
    "    nn.Linear(tensor_x_training.shape[1], parameter),\n",
    "\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(parameter, parameter),\n",
    "\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(parameter, parameter),\n",
    "\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(parameter, 1),\n",
    "\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "while True:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(tensor_x_training)\n",
    "    loss = loss_fn(outputs, tensor_y_training.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate validation loss\n",
    "    with torch.no_grad():\n",
    "        validation_outputs = model(tensor_x_validation)\n",
    "        validation_loss = loss_fn(validation_outputs, tensor_y_validation.unsqueeze(1))\n",
    "\n",
    "        r2 = r2_score(tensor_y_validation.numpy(), validation_outputs.numpy())\n",
    "\n",
    "#        if r2 > r2_min[\"r2\"]:\n",
    "#            r2_min[\"r2\"] = r2\n",
    "#            r2_min[\"parameter\"] = parameter\n",
    "#            r2_min[\"learning_rate\"] = learning_rate\n",
    "\n",
    "    # check for early stopping\n",
    "    if validation_loss >= best_validation_loss:\n",
    "        break \n",
    "    \n",
    "    # stop if the timer has reached 9 minutes\n",
    "    if time.time() - start > 540:\n",
    "        print(\"timer has reached 9 minutes\")\n",
    "        print(\"r2 min : \", r2)\n",
    "        break\n",
    "\n",
    "    best_validation_loss = validation_loss\n",
    "            \n",
    "\n",
    "# print(\"r2 min : \", r2_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the validation set against the output of the model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available and use it, otherwise use the CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Generate model predictions on the validation set\n",
    "with torch.no_grad():\n",
    "    tensor_x_validation = tensor_x_validation.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    validation_outputs = model(tensor_x_validation).cpu().numpy()\n",
    "\n",
    "# Convert the target tensor to a NumPy array\n",
    "validation_targets = tensor_y_validation.cpu().numpy()\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(validation_targets.shape[0]), validation_targets, label='Actual')\n",
    "plt.scatter(range(validation_outputs.shape[0]), validation_outputs, label='Predicted', marker='x')\n",
    "plt.xlabel('Validation Data Index')\n",
    "plt.ylabel('Target Value')\n",
    "plt.legend()\n",
    "plt.title('Actual vs. Predicted Values for the Validation Set')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(\n",
    "\n",
    "#     nn.Linear(tensor_x_training.shape[1], parameter),\n",
    "\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(parameter, parameter),\n",
    "\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(parameter, 1),\n",
    "# )\n",
    "\n",
    "# after 23 minutes, 8 parameters\n",
    "# r2:  0.9022029945690702\n",
    "# best validation loss:  tensor(0.0007)  validation loss:  tensor(0.0007)\n",
    "\n",
    "# after 13 minutes, 16 parameters\n",
    "# r2:  0.9024288425404208\n",
    "# best validation loss:  tensor(0.0007)  validation loss:  tensor(0.0007)\n",
    "\n",
    "# after 9 minutes, 32 parameters\n",
    "# r2:  0.9110110570893579\n",
    "# best validation loss:  tensor(0.0006)  validation loss:  tensor(0.0006)\n",
    "\n",
    "# after 9 minutes, 64 parameters\n",
    "#r2:  0.8424793580733347\n",
    "#best validation loss:  tensor(0.0011)  validation loss:  tensor(0.0011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(\n",
    "\n",
    "#     nn.Linear(tensor_x_training.shape[1], parameter),\n",
    "\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(parameter, parameter),\n",
    "\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(parameter, parameter),\n",
    "\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(parameter, 1),\n",
    "\n",
    "# )\n",
    "\n",
    "# after 9 minutes, 8 parameters\n",
    "\n",
    "# timer has reached 9 minutes\n",
    "# r2 min :  0.8209289690997417\n",
    "\n",
    "# current r2 min :  {'r2': 0.872825849225731, 'parameter': 8, 'learning_rate': 0.001}\n",
    "\n",
    "# testing out parameter:  8  and learning rate:  0.01\n",
    "# current r2 min :  {'r2': 0.872825849225731, 'parameter': 8, 'learning_rate': 0.001}\n",
    "# testing out parameter:  16  and learning rate:  0.0001\n",
    "# current r2 min :  {'r2': 0.872825849225731, 'parameter': 8, 'learning_rate': 0.001}\n",
    "# testing out parameter:  16  and learning rate:  0.001\n",
    "# current r2 min :  {'r2': 0.9359466184869851, 'parameter': 16, 'learning_rate': 0.0001}\n",
    "# testing out parameter:  16  and learning rate:  0.01\n",
    "# current r2 min :  {'r2': 0.9359466184869851, 'parameter': 16, 'learning_rate': 0.0001}\n",
    "# testing out parameter:  32  and learning rate:  0.0001\n",
    "# current r2 min :  {'r2': 0.9359466184869851, 'parameter': 16, 'learning_rate': 0.0001}\n",
    "# testing out parameter:  32  and learning rate:  0.001\n",
    "# current r2 min :  {'r2': 0.9362101278204871, 'parameter': 32, 'learning_rate': 0.0001}\n",
    "\n",
    "\n",
    "# r2 min :  {'r2': 0.9362101278204871, 'parameter': 32, 'learning_rate': 0.0001}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
